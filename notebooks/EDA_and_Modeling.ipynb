{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf272538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae69c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/nikhilprao/Documents/heart-failure-prediction-ml/data/heart_failure_clinical_records_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25251b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f935fbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       299 non-null    float64\n",
      " 1   anaemia                   299 non-null    int64  \n",
      " 2   creatinine_phosphokinase  299 non-null    int64  \n",
      " 3   diabetes                  299 non-null    int64  \n",
      " 4   ejection_fraction         299 non-null    int64  \n",
      " 5   high_blood_pressure       299 non-null    int64  \n",
      " 6   platelets                 299 non-null    float64\n",
      " 7   serum_creatinine          299 non-null    float64\n",
      " 8   serum_sodium              299 non-null    int64  \n",
      " 9   sex                       299 non-null    int64  \n",
      " 10  smoking                   299 non-null    int64  \n",
      " 11  time                      299 non-null    int64  \n",
      " 12  DEATH_EVENT               299 non-null    int64  \n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 30.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3178ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.833893</td>\n",
       "      <td>0.431438</td>\n",
       "      <td>581.839465</td>\n",
       "      <td>0.418060</td>\n",
       "      <td>38.083612</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>263358.029264</td>\n",
       "      <td>1.39388</td>\n",
       "      <td>136.625418</td>\n",
       "      <td>0.648829</td>\n",
       "      <td>0.32107</td>\n",
       "      <td>130.260870</td>\n",
       "      <td>0.32107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.894809</td>\n",
       "      <td>0.496107</td>\n",
       "      <td>970.287881</td>\n",
       "      <td>0.494067</td>\n",
       "      <td>11.834841</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>97804.236869</td>\n",
       "      <td>1.03451</td>\n",
       "      <td>4.412477</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>0.46767</td>\n",
       "      <td>77.614208</td>\n",
       "      <td>0.46767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25100.000000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212500.000000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262000.000000</td>\n",
       "      <td>1.10000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>582.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>303500.000000</td>\n",
       "      <td>1.40000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>850000.000000</td>\n",
       "      <td>9.40000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age     anaemia  creatinine_phosphokinase    diabetes  \\\n",
       "count  299.000000  299.000000                299.000000  299.000000   \n",
       "mean    60.833893    0.431438                581.839465    0.418060   \n",
       "std     11.894809    0.496107                970.287881    0.494067   \n",
       "min     40.000000    0.000000                 23.000000    0.000000   \n",
       "25%     51.000000    0.000000                116.500000    0.000000   \n",
       "50%     60.000000    0.000000                250.000000    0.000000   \n",
       "75%     70.000000    1.000000                582.000000    1.000000   \n",
       "max     95.000000    1.000000               7861.000000    1.000000   \n",
       "\n",
       "       ejection_fraction  high_blood_pressure      platelets  \\\n",
       "count         299.000000           299.000000     299.000000   \n",
       "mean           38.083612             0.351171  263358.029264   \n",
       "std            11.834841             0.478136   97804.236869   \n",
       "min            14.000000             0.000000   25100.000000   \n",
       "25%            30.000000             0.000000  212500.000000   \n",
       "50%            38.000000             0.000000  262000.000000   \n",
       "75%            45.000000             1.000000  303500.000000   \n",
       "max            80.000000             1.000000  850000.000000   \n",
       "\n",
       "       serum_creatinine  serum_sodium         sex    smoking        time  \\\n",
       "count         299.00000    299.000000  299.000000  299.00000  299.000000   \n",
       "mean            1.39388    136.625418    0.648829    0.32107  130.260870   \n",
       "std             1.03451      4.412477    0.478136    0.46767   77.614208   \n",
       "min             0.50000    113.000000    0.000000    0.00000    4.000000   \n",
       "25%             0.90000    134.000000    0.000000    0.00000   73.000000   \n",
       "50%             1.10000    137.000000    1.000000    0.00000  115.000000   \n",
       "75%             1.40000    140.000000    1.000000    1.00000  203.000000   \n",
       "max             9.40000    148.000000    1.000000    1.00000  285.000000   \n",
       "\n",
       "       DEATH_EVENT  \n",
       "count    299.00000  \n",
       "mean       0.32107  \n",
       "std        0.46767  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        1.00000  \n",
       "max        1.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d0ecaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                         0\n",
       "anaemia                     0\n",
       "creatinine_phosphokinase    0\n",
       "diabetes                    0\n",
       "ejection_fraction           0\n",
       "high_blood_pressure         0\n",
       "platelets                   0\n",
       "serum_creatinine            0\n",
       "serum_sodium                0\n",
       "sex                         0\n",
       "smoking                     0\n",
       "time                        0\n",
       "DEATH_EVENT                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f5b382f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1.192945</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096174</td>\n",
       "      <td>1</td>\n",
       "      <td>1.854958</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016816</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>-2.639086</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.964571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.192945</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.391095</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201166</td>\n",
       "      <td>-0.768683</td>\n",
       "      <td>-1.277026</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.726094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-1.586025</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.342574</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.953749</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.515749</td>\n",
       "      <td>-0.090900</td>\n",
       "      <td>-0.141976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.842246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-1.333392</td>\n",
       "      <td>0</td>\n",
       "      <td>1.525979</td>\n",
       "      <td>1</td>\n",
       "      <td>1.854958</td>\n",
       "      <td>0</td>\n",
       "      <td>4.902082</td>\n",
       "      <td>-0.575031</td>\n",
       "      <td>0.312044</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.906697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-0.912335</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.475748</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162199</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.034392</td>\n",
       "      <td>-0.671857</td>\n",
       "      <td>-1.504036</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.577396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "225  1.192945        0                  0.096174         1           1.854958   \n",
       "78   1.192945        1                 -0.391095         1          -0.007077   \n",
       "66  -1.586025        1                 -0.342574         1          -1.953749   \n",
       "296 -1.333392        0                  1.525979         1           1.854958   \n",
       "192 -0.912335        1                 -0.475748         1           0.162199   \n",
       "\n",
       "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "225                    0   0.016816          0.005926     -2.639086    0   \n",
       "78                     1   0.201166         -0.768683     -1.277026    1   \n",
       "66                     0  -0.515749         -0.090900     -0.141976    0   \n",
       "296                    0   4.902082         -0.575031      0.312044    0   \n",
       "192                    0  -0.034392         -0.671857     -1.504036    1   \n",
       "\n",
       "     smoking      time  \n",
       "225        0  0.964571  \n",
       "78         1 -0.726094  \n",
       "66         0 -0.842246  \n",
       "296        0  1.906697  \n",
       "192        0  0.577396  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=[\"DEATH_EVENT\"])\n",
    "y = df[\"DEATH_EVENT\"]\n",
    "\n",
    "# Standardize continuous variables (exclude binary/categorical columns)\n",
    "continuous_cols = [\"age\", \"creatinine_phosphokinase\", \"ejection_fraction\",\n",
    "                   \"platelets\", \"serum_creatinine\", \"serum_sodium\", \"time\"]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "X_scaled[continuous_cols] = scaler.fit_transform(X[continuous_cols])\n",
    "\n",
    "# Split into train and test sets (though we will train on small sample for now)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc4ac0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Death Event Distribution'}, xlabel='DEATH_EVENT'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"DEATH_EVENT\"].value_counts().plot(kind='bar', title='Death Event Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bedc7a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:39:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define models and their hyperparameter grids\n",
    "models = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(max_iter=1000),\n",
    "        \"params\": {\n",
    "            \"C\": [0.01, 0.1, 1, 10],\n",
    "            \"penalty\": [\"l1\", \"l2\"],\n",
    "            \"solver\": [\"liblinear\"]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100],\n",
    "            \"max_depth\": [None, 5, 10],\n",
    "            \"min_samples_split\": [2, 5]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100],\n",
    "            \"max_depth\": [3, 6],\n",
    "            \"learning_rate\": [0.01, 0.1],\n",
    "            \"subsample\": [0.8, 1]\n",
    "        }\n",
    "    },\n",
    "    \"NeuralNetwork\": {\n",
    "        \"model\": MLPClassifier(max_iter=1000),\n",
    "        \"params\": {\n",
    "            \"hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
    "            \"activation\": [\"relu\", \"tanh\"],\n",
    "            \"solver\": [\"adam\", \"sgd\"],\n",
    "            \"alpha\": [0.0001, 0.001]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train and tune each model using GridSearchCV\n",
    "best_models = {}\n",
    "for name, mp in models.items():\n",
    "    clf = GridSearchCV(mp[\"model\"], mp[\"params\"], cv=3, scoring=\"f1\", n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_models[name] = {\n",
    "        \"best_estimator\": clf.best_estimator_,\n",
    "        \"best_params\": clf.best_params_,\n",
    "        \"test_score\": clf.score(X_test, y_test),\n",
    "        \"report\": classification_report(y_test, clf.predict(X_test), output_dict=True)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f27d7443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'best_estimator': LogisticRegression(C=0.1, max_iter=1000, penalty='l1', solver='liblinear'),\n",
       "  'best_params': {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  'test_score': 0.6538461538461537,\n",
       "  'report': {'0': {'precision': 0.7407407407407407,\n",
       "    'recall': 0.9090909090909091,\n",
       "    'f1-score': 0.8163265306122449,\n",
       "    'support': 44.0},\n",
       "   '1': {'precision': 0.8095238095238095,\n",
       "    'recall': 0.5483870967741935,\n",
       "    'f1-score': 0.6538461538461537,\n",
       "    'support': 31.0},\n",
       "   'accuracy': 0.76,\n",
       "   'macro avg': {'precision': 0.7751322751322751,\n",
       "    'recall': 0.7287390029325513,\n",
       "    'f1-score': 0.7350863422291993,\n",
       "    'support': 75.0},\n",
       "   'weighted avg': {'precision': 0.7691710758377425,\n",
       "    'recall': 0.76,\n",
       "    'f1-score': 0.7491679748822606,\n",
       "    'support': 75.0}}},\n",
       " 'RandomForest': {'best_estimator': RandomForestClassifier(max_depth=5, n_estimators=50),\n",
       "  'best_params': {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 50},\n",
       "  'test_score': 0.6399999999999999,\n",
       "  'report': {'0': {'precision': 0.7321428571428571,\n",
       "    'recall': 0.9318181818181818,\n",
       "    'f1-score': 0.82,\n",
       "    'support': 44.0},\n",
       "   '1': {'precision': 0.8421052631578947,\n",
       "    'recall': 0.5161290322580645,\n",
       "    'f1-score': 0.6399999999999999,\n",
       "    'support': 31.0},\n",
       "   'accuracy': 0.76,\n",
       "   'macro avg': {'precision': 0.787124060150376,\n",
       "    'recall': 0.7239736070381231,\n",
       "    'f1-score': 0.73,\n",
       "    'support': 75.0},\n",
       "   'weighted avg': {'precision': 0.777593984962406,\n",
       "    'recall': 0.76,\n",
       "    'f1-score': 0.7455999999999999,\n",
       "    'support': 75.0}}},\n",
       " 'XGBoost': {'best_estimator': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric='logloss',\n",
       "                feature_types=None, feature_weights=None, gamma=None,\n",
       "                grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "                num_parallel_tree=None, ...),\n",
       "  'best_params': {'learning_rate': 0.1,\n",
       "   'max_depth': 6,\n",
       "   'n_estimators': 100,\n",
       "   'subsample': 0.8},\n",
       "  'test_score': 0.6785714285714285,\n",
       "  'report': {'0': {'precision': 0.76,\n",
       "    'recall': 0.8636363636363636,\n",
       "    'f1-score': 0.8085106382978724,\n",
       "    'support': 44.0},\n",
       "   '1': {'precision': 0.76,\n",
       "    'recall': 0.6129032258064516,\n",
       "    'f1-score': 0.6785714285714285,\n",
       "    'support': 31.0},\n",
       "   'accuracy': 0.76,\n",
       "   'macro avg': {'precision': 0.76,\n",
       "    'recall': 0.7382697947214076,\n",
       "    'f1-score': 0.7435410334346504,\n",
       "    'support': 75.0},\n",
       "   'weighted avg': {'precision': 0.76,\n",
       "    'recall': 0.76,\n",
       "    'f1-score': 0.7548024316109423,\n",
       "    'support': 75.0}}},\n",
       " 'NeuralNetwork': {'best_estimator': MLPClassifier(activation='tanh', alpha=0.001, max_iter=1000, solver='sgd'),\n",
       "  'best_params': {'activation': 'tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (100,),\n",
       "   'solver': 'sgd'},\n",
       "  'test_score': 0.5531914893617021,\n",
       "  'report': {'0': {'precision': 0.6949152542372882,\n",
       "    'recall': 0.9318181818181818,\n",
       "    'f1-score': 0.796116504854369,\n",
       "    'support': 44.0},\n",
       "   '1': {'precision': 0.8125,\n",
       "    'recall': 0.41935483870967744,\n",
       "    'f1-score': 0.5531914893617021,\n",
       "    'support': 31.0},\n",
       "   'accuracy': 0.72,\n",
       "   'macro avg': {'precision': 0.753707627118644,\n",
       "    'recall': 0.6755865102639296,\n",
       "    'f1-score': 0.6746539971080356,\n",
       "    'support': 75.0},\n",
       "   'weighted avg': {'precision': 0.7435169491525424,\n",
       "    'recall': 0.72,\n",
       "    'f1-score': 0.6957074984507333,\n",
       "    'support': 75.0}}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c3993d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model                                        Best Params  \\\n",
      "0  LogisticRegression  {'C': 0.1, 'penalty': 'l1', 'solver': 'libline...   \n",
      "1        RandomForest  {'max_depth': None, 'min_samples_split': 5, 'n...   \n",
      "2             XGBoost  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
      "3       NeuralNetwork  {'activation': 'relu', 'alpha': 0.001, 'hidden...   \n",
      "\n",
      "   F1 Score  \n",
      "0  0.653846  \n",
      "1  0.615385  \n",
      "2  0.641509  \n",
      "3  0.627451  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": name,\n",
    "        \"Best Params\": result[\"best_params\"],\n",
    "        \"F1 Score\": result[\"test_score\"]\n",
    "    } for name, result in best_models.items()\n",
    "])\n",
    "\n",
    "# Display in console\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "342a8253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.065249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-0.044721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.010264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetwork</td>\n",
       "      <td>-0.099707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  R2 Score\n",
       "0  LogisticRegression  0.065249\n",
       "1        RandomForest -0.044721\n",
       "2             XGBoost  0.010264\n",
       "3       NeuralNetwork -0.099707"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run minimal setup due to environment reset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define and train models with minimal params for rerun\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"NeuralNetwork\": MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Fit models and compute R2\n",
    "r2_scores = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    r2_scores.append({\n",
    "        \"Model\": name,\n",
    "        \"R2 Score\": score\n",
    "    })\n",
    "\n",
    "# Show results\n",
    "r2_df = pd.DataFrame(r2_scores)\n",
    "r2_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9f7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nikhilprao/Documents/heart-failure-prediction-ml/models/best_model_logistic_regression.pkl'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "# Train the best logistic regression model again\n",
    "logistic = LogisticRegression(max_iter=1000, C=0.1, penalty='l1', solver='liblinear')\n",
    "logistic.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "save_path = \"/Users/nikhilprao/Documents/heart-failure-prediction-ml/models/best_model_logistic_regression.pkl\"\n",
    "joblib.dump(logistic, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4fb5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dc5e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load model\n",
    "model = joblib.load(\"/Users/nikhilprao/Documents/heart-failure-prediction-ml/models/best_model_logistic_regression.pkl\")\n",
    "\n",
    "# Load original dataset\n",
    "df = pd.read_csv(\"/Users/nikhilprao/Documents/heart-failure-prediction-ml/data/heart_failure_clinical_records_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71b5558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop(columns=[\"DEATH_EVENT\"])\n",
    "y = df[\"DEATH_EVENT\"]\n",
    "\n",
    "# Standardize numerical columns (match training)\n",
    "continuous_cols = [\"age\", \"creatinine_phosphokinase\", \"ejection_fraction\",\n",
    "                   \"platelets\", \"serum_creatinine\", \"serum_sodium\", \"time\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "X_scaled[continuous_cols] = scaler.fit_transform(X[continuous_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6565c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict label and probability\n",
    "df[\"PREDICTED\"] = model.predict(X_scaled)\n",
    "df[\"RISK_SCORE\"] = model.predict_proba(X_scaled)[:, 1]  # Probability of class 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a039c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"heart_failure_predictions_tableau.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87057177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEATH_EVENT\n",
       "0    203\n",
       "1     96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"DEATH_EVENT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937613d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
